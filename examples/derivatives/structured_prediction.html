
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Structured prediction &#8212; CVXPY 1.2 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/cvxpy_alabaster.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="structured-prediction">
<h1>Structured prediction<a class="headerlink" href="#structured-prediction" title="Permalink to this headline">¶</a></h1>
<p>In this
example<span class="math notranslate nohighlight">\(\newcommand{\reals}{\mathbf{R}}\)</span><span class="math notranslate nohighlight">\(\newcommand{\ones}{\mathbf{1}}\)</span>,
we fit a regression model to structured data, using an LLCP. The
training dataset <span class="math notranslate nohighlight">\(\mathcal D\)</span> contains <span class="math notranslate nohighlight">\(N\)</span> input-output
pairs <span class="math notranslate nohighlight">\((x, y)\)</span>, where <span class="math notranslate nohighlight">\(x \in \reals^{n}_{++}\)</span> is an input
and <span class="math notranslate nohighlight">\(y \in \reals^{m}_{++}\)</span> is an outputs. The entries of each
output <span class="math notranslate nohighlight">\(y\)</span> are sorted in ascending order, meaning
<span class="math notranslate nohighlight">\(y_1 \leq y_2 \leq \cdots \leq y_m\)</span>.</p>
<p>Our regression model <span class="math notranslate nohighlight">\(\phi : \reals^{n}_{++} \to \reals^{m}_{++}\)</span>
takes as input a vector <span class="math notranslate nohighlight">\(x \in \reals^{n}_{++}\)</span>, and solves an
LLCP to produce a prediction <span class="math notranslate nohighlight">\(\hat y \in \reals^{m}_{++}\)</span>. In
particular, the solution of the LLCP is model’s prediction. The model is
of the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{equation}
\begin{array}{lll}
\phi(x) = &amp;
\mbox{argmin} &amp; \ones^T (z/y + y / z) \\
&amp; \mbox{subject to} &amp;  y_i \leq y_{i+1}, \quad i=1, \ldots, m-1 \\
&amp;&amp; z_i = c_i x_1^{A_{i1}}x_2^{A_{i2}}\cdots x_n^{A_{in}}, \quad i = 1, \ldots, m.
\end{array}\label{e-model}
\end{equation}\end{split}\]</div>
<p>Here, the minimization is over <span class="math notranslate nohighlight">\(y \in \reals^{m}_{++}\)</span> and an
auxiliary variable <span class="math notranslate nohighlight">\(z \in \reals^{m}_{++}\)</span>, <span class="math notranslate nohighlight">\(\phi(x)\)</span> is the
optimal value of <span class="math notranslate nohighlight">\(y\)</span>, and the parameters are
<span class="math notranslate nohighlight">\(c \in \reals^{m}_{++}\)</span> and <span class="math notranslate nohighlight">\(A \in \reals^{m \times n}\)</span>. The
ratios in the objective are meant elementwise, as is the inequality
<span class="math notranslate nohighlight">\(y \leq z\)</span>, and <span class="math notranslate nohighlight">\(\ones\)</span> denotes the vector of all ones.
Given a vector <span class="math notranslate nohighlight">\(x\)</span>, this model finds a sorted vector
<span class="math notranslate nohighlight">\(\hat y\)</span> whose entries are close to monomial functions of
<span class="math notranslate nohighlight">\(x\)</span> (which are the entries of <span class="math notranslate nohighlight">\(z\)</span>), as measured by the
fractional error.</p>
<p>The training loss <span class="math notranslate nohighlight">\(\mathcal{L}(\phi)\)</span> of the model on the training
set is the mean squared loss</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\phi) = \frac{1}{N}\sum_{(x, y) \in \mathcal D} \|y - \phi(x)\|_2^2.\]</div>
<p>We emphasize that <span class="math notranslate nohighlight">\(\mathcal{L}(\phi)\)</span> depends on <span class="math notranslate nohighlight">\(c\)</span> and
<span class="math notranslate nohighlight">\(A\)</span>. In this example, we fit the parameters <span class="math notranslate nohighlight">\(c\)</span> and
<span class="math notranslate nohighlight">\(A\)</span> in the LLCP to minimize the training loss
<span class="math notranslate nohighlight">\(\mathcal{L}(\phi)\)</span>.</p>
<p><strong>Fitting.</strong> We fit the parameters by an iterative projected gradient
descent method on <span class="math notranslate nohighlight">\(\mathcal L(\phi)\)</span>. In each iteration, we first
compute predictions <span class="math notranslate nohighlight">\(\phi(x)\)</span> for each input in the training set;
this requires solving <span class="math notranslate nohighlight">\(N\)</span> LLCPs. Next, we evaluate the training
loss <span class="math notranslate nohighlight">\(\mathcal L(\phi)\)</span>. To update the parameters, we compute the
gradient <span class="math notranslate nohighlight">\(\nabla \mathcal L(\phi)\)</span> of the training loss with
respect to the parameters <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(A\)</span>. This requires
differentiating through the solution map of the LLCP. We can compute
this gradient efficiently, using the <code class="docutils literal notranslate"><span class="pre">backward</span></code> method in CVXPY (or
CVXPY Layers). Finally, we subtract a small multiple of the gradient
from the parameters. Care must be taken to ensure that <span class="math notranslate nohighlight">\(c\)</span> is
strictly positive; this can be done by clamping the entries of <span class="math notranslate nohighlight">\(c\)</span>
at some small threshold slightly above zero. We run this method for a
fixed number of iterations.</p>
<p>This example is described in the paper <a class="reference external" href="http://web.stanford.edu/~boyd/papers/pdf/diff_llcvx.pdf">Differentiating through Log-Log
Convex
Programs</a>.</p>
<p>Shane Barratt formulated the idea of using an optimization layer to
regress on sorted vectors.</p>
<p><strong>Requirements.</strong> This example requires PyTorch and CvxpyLayers &gt;=
v0.1.3.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from cvxpylayers.torch import CvxpyLayer


import cvxpy as cp
import matplotlib.pyplot as plt
import numpy as np
import torch

torch.set_default_tensor_type(torch.DoubleTensor)
%matplotlib inline
</pre></div>
</div>
<section id="data-generation">
<h2>Data generation<a class="headerlink" href="#data-generation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n = 20
m = 10

# Number of training input-output pairs
N = 100

# Number of validation pairs
N_val = 50
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>torch.random.manual_seed(243)
np.random.seed(243)

normal = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(n), torch.eye(n))
lognormal = lambda batch: torch.exp(normal.sample(torch.tensor([batch])))

A_true = torch.randn((m, n)) / 10
c_true = np.abs(torch.randn(m))
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def generate_data(num_points, seed):
    torch.random.manual_seed(seed)
    np.random.seed(seed)

    latent = lognormal(num_points)
    noise = lognormal(num_points)
    inputs = noise + latent

    input_cp = cp.Parameter(pos=True, shape=(n,))
    prediction = cp.multiply(c_true.numpy(), cp.gmatmul(A_true.numpy(), input_cp))
    y = cp.Variable(pos=True, shape=(m,))
    objective_fn = cp.sum(prediction / y + y/prediction)
    constraints = []
    for i in range(m-1):
        constraints += [y[i] &lt;= y[i+1]]
    problem = cp.Problem(cp.Minimize(objective_fn), constraints)

    outputs = []
    for i in range(num_points):
        input_cp.value = inputs[i, :].numpy()
        problem.solve(cp.SCS, gp=True)
        outputs.append(y.value)
    return inputs, torch.stack([torch.tensor(t) for t in outputs])
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_inputs, train_outputs = generate_data(N, 243)
plt.plot(train_outputs[0, :].numpy())
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x12b367cd0</span><span class="o">&gt;</span><span class="p">]</span>
</pre></div>
</div>
<img alt="../../_images/structured_prediction_6_1.png" src="../../_images/structured_prediction_6_1.png" />
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>val_inputs, val_outputs = generate_data(N_val, 0)
plt.plot(val_outputs[0, :].numpy())
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span> <span class="n">at</span> <span class="mh">0x12da7e410</span><span class="o">&gt;</span><span class="p">]</span>
</pre></div>
</div>
<img alt="../../_images/structured_prediction_7_1.png" src="../../_images/structured_prediction_7_1.png" />
<section id="monomial-fit-to-each-component">
<h3>Monomial fit to each component<a class="headerlink" href="#monomial-fit-to-each-component" title="Permalink to this headline">¶</a></h3>
<p>We will initialize the parameters in our LLCP model by fitting monomials
to the training data, without enforcing the monotonicity constraint.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>log_c = cp.Variable(shape=(m,1))
theta = cp.Variable(shape=(n, m))
inputs_np = train_inputs.numpy()
log_outputs_np = np.log(train_outputs.numpy()).T
log_inputs_np = np.log(inputs_np).T
offsets = cp.hstack([log_c]*N)
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>cp_preds = theta.T @ log_inputs_np + offsets
objective_fn = (1/N) * cp.sum_squares(cp_preds - log_outputs_np)
lstq_problem = cp.Problem(cp.Minimize(objective_fn))
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lstq_problem.is_dcp()
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lstq_problem.solve(verbose=True)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----------------------------------------------------------------</span>
           <span class="n">OSQP</span> <span class="n">v0</span><span class="mf">.6.0</span>  <span class="o">-</span>  <span class="n">Operator</span> <span class="n">Splitting</span> <span class="n">QP</span> <span class="n">Solver</span>
              <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">Bartolomeo</span> <span class="n">Stellato</span><span class="p">,</span>  <span class="n">Goran</span> <span class="n">Banjac</span>
        <span class="n">University</span> <span class="n">of</span> <span class="n">Oxford</span>  <span class="o">-</span>  <span class="n">Stanford</span> <span class="n">University</span> <span class="mi">2019</span>
<span class="o">-----------------------------------------------------------------</span>
<span class="n">problem</span><span class="p">:</span>  <span class="n">variables</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">1210</span><span class="p">,</span> <span class="n">constraints</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">1000</span>
          <span class="n">nnz</span><span class="p">(</span><span class="n">P</span><span class="p">)</span> <span class="o">+</span> <span class="n">nnz</span><span class="p">(</span><span class="n">A</span><span class="p">)</span> <span class="o">=</span> <span class="mi">23000</span>
<span class="n">settings</span><span class="p">:</span> <span class="n">linear</span> <span class="n">system</span> <span class="n">solver</span> <span class="o">=</span> <span class="n">qdldl</span><span class="p">,</span>
          <span class="n">eps_abs</span> <span class="o">=</span> <span class="mf">1.0e-05</span><span class="p">,</span> <span class="n">eps_rel</span> <span class="o">=</span> <span class="mf">1.0e-05</span><span class="p">,</span>
          <span class="n">eps_prim_inf</span> <span class="o">=</span> <span class="mf">1.0e-04</span><span class="p">,</span> <span class="n">eps_dual_inf</span> <span class="o">=</span> <span class="mf">1.0e-04</span><span class="p">,</span>
          <span class="n">rho</span> <span class="o">=</span> <span class="mf">1.00e-01</span> <span class="p">(</span><span class="n">adaptive</span><span class="p">),</span>
          <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.00e-06</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1.60</span><span class="p">,</span> <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">10000</span>
          <span class="n">check_termination</span><span class="p">:</span> <span class="n">on</span> <span class="p">(</span><span class="n">interval</span> <span class="mi">25</span><span class="p">),</span>
          <span class="n">scaling</span><span class="p">:</span> <span class="n">on</span><span class="p">,</span> <span class="n">scaled_termination</span><span class="p">:</span> <span class="n">off</span>
          <span class="n">warm</span> <span class="n">start</span><span class="p">:</span> <span class="n">on</span><span class="p">,</span> <span class="n">polish</span><span class="p">:</span> <span class="n">on</span><span class="p">,</span> <span class="n">time_limit</span><span class="p">:</span> <span class="n">off</span>

<span class="nb">iter</span>   <span class="n">objective</span>    <span class="n">pri</span> <span class="n">res</span>    <span class="n">dua</span> <span class="n">res</span>    <span class="n">rho</span>        <span class="n">time</span>
   <span class="mi">1</span>   <span class="mf">0.0000e+00</span>   <span class="mf">3.30e+00</span>   <span class="mf">1.22e+04</span>   <span class="mf">1.00e-01</span>   <span class="mf">3.06e-03</span><span class="n">s</span>
  <span class="mi">50</span>   <span class="mf">1.0014e-02</span>   <span class="mf">1.72e-07</span>   <span class="mf">1.64e-07</span>   <span class="mf">1.75e-03</span>   <span class="mf">7.37e-03</span><span class="n">s</span>
<span class="n">plsh</span>   <span class="mf">1.0014e-02</span>   <span class="mf">1.56e-15</span>   <span class="mf">1.17e-14</span>   <span class="o">--------</span>   <span class="mf">9.68e-03</span><span class="n">s</span>

<span class="n">status</span><span class="p">:</span>               <span class="n">solved</span>
<span class="n">solution</span> <span class="n">polish</span><span class="p">:</span>      <span class="n">successful</span>
<span class="n">number</span> <span class="n">of</span> <span class="n">iterations</span><span class="p">:</span> <span class="mi">50</span>
<span class="n">optimal</span> <span class="n">objective</span><span class="p">:</span>    <span class="mf">0.0100</span>
<span class="n">run</span> <span class="n">time</span><span class="p">:</span>             <span class="mf">9.68e-03</span><span class="n">s</span>
<span class="n">optimal</span> <span class="n">rho</span> <span class="n">estimate</span><span class="p">:</span> <span class="mf">8.77e-05</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.010014212812318733</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>c = torch.exp(torch.tensor(log_c.value)).squeeze()
lstsq_val_preds = []
for i in range(N_val):
    inp = val_inputs[i, :].numpy()
    pred = cp.multiply(c,cp.gmatmul(theta.T.value, inp))
    lstsq_val_preds.append(pred.value)
</pre></div>
</div>
</section>
<section id="fitting">
<h3>Fitting<a class="headerlink" href="#fitting" title="Permalink to this headline">¶</a></h3>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>A_param = cp.Parameter(shape=(m, n))
c_param = cp.Parameter(pos=True, shape=(m,))
x_slack = cp.Variable(pos=True, shape=(n,))
x_param = cp.Parameter(pos=True, shape=(n,))
y = cp.Variable(pos=True, shape=(m,))

prediction = cp.multiply(c_param, cp.gmatmul(A_param, x_slack))
objective_fn = cp.sum(prediction / y + y / prediction)
constraints = [x_slack == x_param]
for i in range(m-1):
    constraints += [y[i] &lt;= y[i+1]]
problem = cp.Problem(cp.Minimize(objective_fn), constraints)
problem.is_dgp(dpp=True)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>A_param.value = np.random.randn(m, n)
x_param.value = np.abs(np.random.randn(n))
c_param.value = np.abs(np.random.randn(m))

layer = CvxpyLayer(problem, parameters=[A_param, c_param, x_param], variables=[y], gp=True)
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>torch.random.manual_seed(1)
A_tch = torch.tensor(theta.T.value)
A_tch.requires_grad_(True)
c_tch = torch.tensor(np.squeeze(np.exp(log_c.value)))
c_tch.requires_grad_(True)
train_losses = []
val_losses = []

lam1 = torch.tensor(1e-1)
lam2 = torch.tensor(1e-1)

opt = torch.optim.SGD([A_tch, c_tch], lr=5e-2)
for epoch in range(10):
    preds = layer(A_tch, c_tch, train_inputs, solver_args={&#39;acceleration_lookback&#39;: 0})[0]
    loss = (preds - train_outputs).pow(2).sum(axis=1).mean(axis=0)

    with torch.no_grad():
        val_preds = layer(A_tch, c_tch, val_inputs, solver_args={&#39;acceleration_lookback&#39;: 0})[0]
        val_loss = (val_preds - val_outputs).pow(2).sum(axis=1).mean(axis=0)

    print(&#39;(epoch {0}) train / val ({1:.4f} / {2:.4f}) &#39;.format(epoch, loss, val_loss))
    train_losses.append(loss.item())
    val_losses.append(val_loss.item())

    opt.zero_grad()
    loss.backward()
    opt.step()
    with torch.no_grad():
        c_tch = torch.max(c_tch, torch.tensor(1e-8))
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">epoch</span> <span class="mi">0</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0018</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">1</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0017</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">2</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0017</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">3</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0017</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">4</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0017</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">5</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0017</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">6</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0016</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">7</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0016</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">8</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0016</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
<span class="p">(</span><span class="n">epoch</span> <span class="mi">9</span><span class="p">)</span> <span class="n">train</span> <span class="o">/</span> <span class="n">val</span> <span class="p">(</span><span class="mf">0.0016</span> <span class="o">/</span> <span class="mf">0.0014</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with torch.no_grad():
    train_preds_tch = layer(A_tch, c_tch, train_inputs)[0]
    train_preds = [t.detach().numpy() for t in train_preds_tch]
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with torch.no_grad():
    val_preds_tch = layer(A_tch, c_tch, val_inputs)[0]
    val_preds = [t.detach().numpy() for t in val_preds_tch]
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = plt.figure()


i = 0
plt.plot(val_preds[i], label=&#39;LLCP&#39;, color=&#39;teal&#39;)
plt.plot(lstsq_val_preds[i], label=&#39;least squares&#39;, linestyle=&#39;--&#39;, color=&#39;gray&#39;)
plt.plot(val_outputs[i], label=&#39;true&#39;, linestyle=&#39;-.&#39;, color=&#39;orange&#39;)
w, h = 8, 3.5
plt.xlabel(r&#39;$i$&#39;)
plt.ylabel(r&#39;$y_i$&#39;)
plt.legend()
plt.show()
</pre></div>
</div>
<img alt="../../_images/structured_prediction_20_0.png" src="../../_images/structured_prediction_20_0.png" />
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">CVXPY</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=cvxpy&repo=cvxpy&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Install</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Examples</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api_reference/cvxpy.html">API Documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index.html">FAQ</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../citing/index.html">Citing CVXPY</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contributing/index.html">Contributing</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../related_projects/index.html">Related Projects</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../updates/index.html">Changes to CVXPY</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../short_course/index.html">CVXPY Short Course</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../license/index.html">License</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script><div>
    <h3>
        Version selector
    </h3>
    <select id="dynamic_selector" name="versions" onchange="if (this.value) window.location.href=this.value">
    </select>
    <script>
        obj = $.getJSON("https://raw.githubusercontent.com/cvxpy/cvxpy/gh-pages/versions.json")
            .done(function (data) {
                const base_url = "https://www.cvxpy.org/"
                let html = "<option value='' selected>Choose version here</option>";
                html += "<option value=" + base_url + ">latest" + ""
                for (let i = 0; i < data.length; i++) {
                    html += "<option value=" + base_url + "version/"  + data[i] + ">" + data[i] + ""
                }
                document.getElementById("dynamic_selector").innerHTML = html;
            });
    </script>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;The CVXPY authors.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.5.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/examples/derivatives/structured_prediction.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/cvxpy/cvxpy" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-50248335-1']);
      _gaq.push(['_setDomainName', 'none']);
      _gaq.push(['_setAllowLinker', true]);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>
    
  </body>
</html>